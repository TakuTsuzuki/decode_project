{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificaton LMPP/ProB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import six\n",
    "import six.moves.cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda\n",
    "from chainer import optimizers\n",
    "from chainer import computational_graph as c\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load&Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpath=os.path.abspath(\"\")\n",
    "foldername = \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 90, 2992)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmpp = np.load(dpath+foldername+\"/lmpp_data.npy\")\n",
    "prob = np.load(dpath+foldername+\"/prob_data.npy\")\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(len(prob[0,0,:]))\n",
    "prob_dat = np.asarray(prob[:,:,shuffle])[:,:,:len(lmpp[0,0,:])]\n",
    "x_data = np.dstack((lmpp,prob_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_data = np.r_[\n",
    "        np.zeros(len(lmpp[0,0,:])),\n",
    "        np.ones(len(lmpp[0,0,:])),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 1, 90, 90)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data =x_data[np.newaxis,:,:,:]\n",
    "x_data = x_data.transpose(3,0,1,2).astype(np.float32)\n",
    "t_data = t_data.astype(np.int32)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Classificaton using size data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYXFWZ7/Hvm4QQkjCpBDm5cCs4hwwiQoJzMFwibVAJ\nDGCPOggaDs0wCmc8ao/jjMD4YKuMKI4SBZU5DtJgHJETJQgiEpUCMmNsHEjCVYxSExLoQEgaSUiT\n23v+qF2dSnd196rOrtqrm9/nefpJ71171/71SlW9tdfaF3N3REREQozKOoCIiAwfKhoiIhJMRUNE\nRIKpaIiISDAVDRERCaaiISIiwVQ0ZEQxs7yZ7TKzUcl0wcwurvE5DjWzV8zMUsjz72Z2XOCyj5nZ\n2/Z2mwM8f09bmNnZZnZrvbYlI5eKhkTJzD5gZr9JPryfM7O7zezkITyVJz/hK7ivcff9fS9PYjKz\ns4GX3X1l4HaPcfcH9mabg20i+cHd7wTeZGZvruP2ZARS0ZDomNkngGuBq4D/BhwCfAM4J8tcQ3Ap\n8N2sQwzg+8CHsw4hw4uKhkTFzCYBnwX+xt2XuPtWd9/p7j9x908ly5iZXWZmq81sg5n9wMwmD2Fb\nJyR7My+bWaeZfSWZ39PFZWYnJns75Z9uM3smWW5UfznMbCzwduD+iu21mdliM7vVzP5oZv9pZsdW\nPF40s3nJ73eb2T9XPHarmd2Y/L6fmX0lWb7LzB40s3HJY3PM7D/MbJOZrTCzUwdoggLw57W2m7y+\nqWhIbE4ExgG3D7DMxyjtdbwNmA5sorQnUquvAde6+yTgCOC23gu4+6+Srqr9gcnAcuDfkoc/OkCO\nI4Fd7v5cr6c8J9nO5OR5lpjZ6PLmKpa7CLjAzN5uZh8E/iz5uwH+GZhNqa2mAH8P7DKzg4C7gM+5\n+2Tgk8APzeyAfv7+p4C8mU3sr4FEelPRkNgcAGxw910DLHMJ8Gl3f87dt1PaM3lfefC7BtuAI83s\nDe7+qrv/epDlrwP+6O7/GJAjB7xS5Tl+4+4/cvedwFcpFcg5vRdy9/XA/wZuARYC/8vdtyTPfRHw\ncXd/3t13uftyd98GLADudvd7kuf4OfAb+t+bKOfLDfJ3i/RQ0ZDYvAS8YZACkAduT7pgNgFPADuA\nqTVu62JgJvCkmXWYWb9dNWZ2CaU9ig8E5tgE7F/lqdaWf0kG2tcCM/rZ7F3AaOApd/+PZN4bKBWa\n31dZ/jDgL8t5kkwnA9P6ef5yvq5+HhfpQ0VDYvMr4DXgLwZYZg0w390nV/yMd/fna9mQu6929w+4\n+4HAl4DFZrZf7+XMbC7wOeDd7r45MMfq0qo2vdfTHVLxvKOAg4HeXVhl/0SpEE03s/OSeRuAbuB/\nVFl+DfDdXnn2d/dr+nn+NwLFXn+TyIBUNCQq7v4ycCXwDTN7t5mNN7N9zOwMM/tSstgNwBfM7FAA\nMzvQzAY6sqrq+RZmtsDMDkwmX6Y0prCr1zKHUBqDuMDdV/d6in5zJN1FPweaeq3zFjP7CzMbA7RS\nKgDLq2R7G9ACXJD8e52ZzUi67b4DfNXMppvZ6GSwfiywCDjbzN6VzB9nZk3JWEe1tjgVuLta24j0\nR0VDouPuXwU+AXwaeIHSN+i/Yffg+NeAHwP3mtkfKe2dnFD5FL2fsp9NnQ48ZmavUDrE9zx3f63X\nOqdROuz3hxVHUD0amONfKH3oV+a4A3g/sBH4IPCeZHyjh5n9CXAz8JFk3GIZcCOlYgGlAe5HgYco\ndeddDYxy97XAu4Er2N1uf8eehaKyLc5LMooEs3rdhMnMvkNpAO4Fd39zMm8K8ANKfa9F4Fx370oe\nuxz4K2An8DF3v7cuwUQayMyWUfrwX2lmbcB/d/cLBlmt7pITDz/o7ucNurBIhXruadwEzO817zJg\nqbvPBH6RTGNmR1P69nV0ss43h3AkjEh03P2U0DPCG8nd71TBkKGo2wezuz9I6QiSSudQ2u0m+bc5\n+f3dwPfdfbu7FykNIp6AyMhS8yVNRGIzpsHbm5ocfw6wnt2HSM5gz8HAtUDl4J3IsOfun806g8je\nyqwLKDlGfaBvXfpGJiISmUbvaaw3s2nu3pkcv/5CMn8dFcevUzp2fV3vlc1MhUREZAjcfa8v9Q+N\n39P4MXBh8vuFwJKK+eeZ2VgzO5zSdXs6qj2Bu0f385nPfCbzDMqkTK/HXMoU9pOmuu1pmNn3KZ08\n9AYze5bSCVtfBG6z0o1gisC5AO7+hJndxu7LMPyNp/2X1lGxWMw6Qh/KFEaZwsWYS5kar25Fw93P\n7+ehd/Sz/BeAL9Qrj4iI7D2dC5GClpaWrCP0oUxhlClcjLmUqfHqdkZ4PZjZcOq1EhGJgpnhw3Qg\nfEQqFApZR+hDmcIoU7isc5mZfgJ+6q3Rh9yKiAyZehoG1oiioe4pERkWki6WrGNErb82UveUiIhk\nQkUjBVn39VajTGGUKVysuaSxVDRERCSYxjREZFio1l/f1toKXV3122guR9vChYMuls/nufHGGznt\ntNN65hUKBebNm0dzczM/+tGPeuavXLmS2bNnc+qpp3LfffcBMGrUKMaPH4+ZMWnSJN7//vfz5S9/\nmVGjRpHP53nhhRcYPXo0EyZM4IwzzuD6669nwoQJfXI0YkxDR0+JyPDV1UVbPl+3p28LvCRIf4e7\nHnjggSxfvpyNGzcyZcoUAG6++WZmzpzZZ/lVq1ZxxBFH8Nvf/pampiZmzpzJJZdcgplx1113MW/e\nPJ577jlOP/10rrrqKq6++uq9/vuGQt1TKYixr1eZwihTuFhzxWzs2LE0Nzdz6623ArBz505uu+02\nPvjBD/Z7JNif/umfMnfuXB5//PE+j82YMYP58+fz2GOP1TX3QFQ0RETq6IILLuCWW24B4Gc/+xnH\nHHMMM2bM6LNcuYg88cQTPPjgg8yePbvPY88++yw//elPOf744xuQvDp1T6Wgqakp6wh9KFMYZQoX\na67YnXjiiWzcuJGnn36aW265hQsvvJBXX321z3LHH388o0ePZsqUKXzoQx/ioosuAkoFo7m5mTFj\nxjBp0iTOOussrrjiikb/GT1UNEaw1ta2mscIczlYuLCtLnlEXq8uuOACrrvuOgqFAu3t7SxatKjP\nMo888ghHHHFEn/lmxh133MG8efMaEXVQKhopKBQK0X0LKxQKdHVBPt9W03rFYm3L1yLWdlKmMLHm\nGg4WLFjAkUceyYUXXsi4ceOyjrNXVDRERFKwbds2uru7e6Z37NjR8/vhhx/OAw88UHVPYrhR0UhB\njN++mpqaaG8vZB1jD7G2U2xizASR5srlgg+LHerzhzrzzDP3mD755JP3OKz2pJNO6vm99yG6jbjQ\nYFp0ct8I1tLSNqTuqfb22tYRaQRdsHBwumDhMBHj8evKFEaZwsWaSxpLRUNERIKpe2oEU/eUjCTq\nnhqcuqdERCQqKhopiLGvV5nCKFO4WHNJY6loiIhIMI1pjGAa05CRRGMag9OYhoiIREVFIwUx9vUq\nUxhlChdrLmksXUZERIatoVzJuRahV32u5ZasA6m87eu4ceN45zvfybe+9S0mTZo0xL8gfRrTGME0\npiEjSbX++qG8xmsR+n44/PDDufHGG/e4JetZZ521xy1Zd+zYwZgxA39PHzVqFKtXr+aII47glVde\n4dxzz+Woo47i2muvDcqre4RLw3V0LKelpa2mdXQPDpHdZsyYwRlnnMFjjz3GqFGjuP7667n22mvZ\ntWsXv//97/n2t7/NNddcw8aNGznllFO44YYbmD59ep/n2X///Tn77LO54447Mvgr+qeikYIY7zMw\n1P7nbdvG1e0eHLG2kzKFiTVXLCpvyXr33Xfznve8h5/85CfccccdPPTQQ+y333788pe/5IorrmDp\n0qUcffTRfPKTn+S8887j/vvv7/M8mzZtYsmSJXtcHTcGGggXEdlL5VuyTp48mblz59LU1NRzS9bL\nL7+cXC7Hvvvuy/e+9z0uvvhiZs2axdixY7n66qv51a9+xZo1a3qe6/jjj2fy5MkceOCBrF27lg9/\n+MNZ/VlVqWikIMZvX8oURpnCxZorBuVbsm7atIliscj111/fc4e+Qw45pGe5559/nsMOO6xnesKE\nCRxwwAGsW7euZ94jjzzCpk2b6O7u5tJLL2Xu3Lm89tprjftjBqGiISJSR5U3WJoxYwbFiptGbdmy\nhZdeeomDDjqoz3pjxozh4osv5plnnuHxxx9vRNQgKhopiPH4dWUKo0zhYs01nJx//vncdNNNrFy5\nktdee40rrriCOXPmcOihh/YsUx7T2LlzJzfddBPjx4+P6jaxGggXkWErlws/EGOoz783et/G9bTT\nTuPzn/88733ve9m0aRMnn3wyt9566x7LHHfccZgZo0aN4qijjuL2228nt7dBUpTJeRpm9rfAxYAD\njwIXAROAHwCHAUXgXHfv6rWeztOowVCOYV+0qJkFC5bUtI7O7ZBG0LWnBjcirz1lZgcBHwXe4u5v\nBkYD5wGXAUvdfSbwi2RaREQiktWYxhhgvJmNAcYDzwHnADcnj98MNGeUrWYx9vUqUxhlChdrLmms\nhhcNd18HfAVYQ6lYdLn7UmCqu69PFlsPTG10NhERGVjDB8LNbDKlvYo88DLw/8xsQeUy7u5mVrXz\nsqWlhXw+D0Aul2PWrFk9x4+Xvwlpuommpia++MV2oEA+X3q8WCw9PtD01q0bKAtZvtJg+crzYmif\nyunQ/K/36fK8LLcvYQqFAu3t7QA9n5dpafhAuJn9JXC6u/91Mn0BMAeYB7zd3TvNbDpwn7sf1Wtd\nDYTXQAPhMpJoIHxwI3IgHPgvYI6Z7Wel49HeATwB3AlcmCxzIVDbJ1eGYuzrVaYwyhQu1lzSWA3v\nnnL3DjNbDDwM7Ej+/b/A/sBtZnYxySG3jc4mInHrfd6DNJ7upzGCqXtKRGD4d0+JiMgwpaKRghj7\nepUpjDKFizGXMjWeioaIiART0UhBjMeRK1MYZQoXYy5lajxd5VYkJW2trdDVNfiCveVytC1cmH4g\nkTpQ0UhB5VmysYixXzXWdkotU1cXbUM4+7at4qY8EGc7QZy5lKnx1D0lIiLBVDRSEOO3CmUKo0zh\nYsylTI2noiEiIsFUNFIQ6/hBbJQpTIyZIM5cytR4KhoiIhJMRSMFMfZhKlMYZQoXYy5lajwVDRER\nCaaikYIY+zCVKYwyhYsxlzI1noqGiIgEU9FIQYx9mMoURpnCxZhLmRpPRUNERIKpaKQgxj5MZQqj\nTOFizKVMjaeiISIiwVQ0UhBjH6YyhVGmcDHmUqbGU9EQEZFgKhopiLEPU5nCKFO4GHMpU+OpaIiI\nSDAVjRTE2IepTGGUKVyMuZSp8VQ0REQkmIpGCmLsw1SmMMoULsZcytR4KhoiIhJMRSMFMfZhKlMY\nZQoXYy5lajwVDRERCaaikYIY+zCVKYwyhYsxlzI1noqGiIgEG5N1gJEgxj7MpqYm2tsLWcfYQ2U7\ntba20dVV2/q5HCxc2Fa3TGVtra3UHA5Y0dEB+XxdMsUgxlzK1HgqGpKJri7I59tqWqdYrG35Ievq\nom0IH/7Ny5aln0UkMuqeSkGMfZjKFEaZwsWYS5kaT0VDRESCZVI0zCxnZovN7Ekze8LM3mpmU8xs\nqZk9bWb3mlkui2xDEWMfpjKFUaZwMeZSpsbLak/ja8Dd7v5G4FjgKeAyYKm7zwR+kUyLiEhEGl40\nzGwSMNfdvwPg7jvc/WXgHODmZLGbgeZGZxuqGPswlSmMMoWLMZcyNV4WexqHAy+a2U1m9rCZfdvM\nJgBT3X19ssx6YGoG2UREZABZFI0xwPHAN939eGALvbqi3N0BzyDbkMTYh6lMYZQpXIy5lKnxsjhP\nYy2w1t0fSqYXA5cDnWY2zd07zWw68EK1lVtaWsgnx9DncjlmzZrV859U3i3UdGm6s7MIFMjnS9PF\nYunxgaa3bt1AWcjyAB0dy2lpaUu2B9Om5Su2X326o2MFEPb85enOziKFQqHu7VdWKJbyNiWvt8Gm\nN2zdSqFYDF6+PN2zvcheP5XTba2tFJ96CoD8tGkAFDs7B5+eOJH2xYszz/96my4UCrS3twP0fF6m\nxUpf6hvLzB4A/trdnzazNmB88tBL7v4lM7sMyLn7Zb3W8yzyDqbygywWpRdNoeYT6BYtambBgiV1\nWadY3F3AhrKdYrGN9va2mtYZTLX/u7aWlqGd3LdoEUsWLKh5vbZikbbkDd5fpqy1tbTQxO6CF7xe\nr78tbTG2VYyZzAx3tzSeK6szwj8KfM/MxgK/By4CRgO3mdnFQBE4N6NsIiLSj0yKhruvBP5nlYfe\n0egsaYjtWwXEee2p8l5GTGL9v4tRrXsZjRBjW8WYKU06I1xERIKpaKSg9wBqDGLMVB7YjkmM7RRj\nJug7cB+DGNsqxkxpUtEQEZFgKhopiLEPM8ZMGtMIE2Mm0JhGqBgzpUlFQ0REgukmTCmI8bjsGPtV\nK8/TqEXhnnugu5uuzctoa2kJXm/5ypXMOe64gTN1dvacjFaW1h34hirG1xOwx4mLsYixrWLMlCYV\nDYlfdzdNuRxFJtZ00l3zsmWDLl+gb7eL7sAn0j91T6Ugxm8VMWaKckwjsm/OEOf/HaitQsWYKU0q\nGiIiEkxFIwUxjh/EmCnK8zR07kEwtVWYGDOladAxDTObMtDj7r4xvTgiIhKzkD2Nh4ENwO+Snw3J\nvP8EflO/aMNHjH2YMWbSmEaYGP/vQG0VKsZMaQopGkuBs9z9AHc/APhz4F53P9zdj6hvPBERiUlI\n0TjR3e8uT7j7T4GT6hdp+ImxDzPGTBrTCBPj/x2orULFmClNIedpPGdmnwYWAQZ8AFhX11TSR2tr\nG11d4ct3dhZZs6Yry3PURGQECika5wOfAW5Pph9I5kmiEX2YXV3UdBe+fB5Wr26uW56h0JhGmFj7\nxNVWYWLMlKZBi4a7vwR8zMwmuPuWBmQSEZFIDTqmYWYnmdkTwFPJ9HFm9s26JxtGYuzDjHH8IMZM\n6qcPp7YKE2OmNIUMhC8E5lM61LZ8q9ZT6xlKRETiFHRGuLuv6TVrRx2yDFsx9mHGOH4QYyb104dT\nW4WJMVOaQgbC15jZyQBmNhb4GPBkXVOJiEiUQvY0LgU+AhxE6VDb2cm0JGLsw4xx/CDGTOqnD6e2\nChNjpjQNuKdhZmOAr7n7BxqUR0REIjbgnoa77wAOM7N9G5RnWIqxDzPG8YMYM6mfPpzaKkyMmdIU\nMqbxB2CZmf0YeDWZ5+7+1frFEhGRGPW7p2Fm301+PQe4K1l2YvKzf/2jDR8x9mHGOH4QYyb104dT\nW4WJMVOaBtrTeIuZzQDWANdRuu6UiIi8jg1UNG4AfgEcQeneGZU8mS/E2YeZzzexbNnCrGPsIasx\njdZ7ltPVPa7fx9tXrNhj+uH1+9F6z3IWzp9T72hVxfh6Ao1phIoxU5r6LRru/nXg62Z2g7tf2sBM\nIqnq6h5HPtcavPz4fVbR1f3LOiYSGb4GPU9DBWNwMfZhxjh+EGWmrhWDL9RgMb6eQGMaoWLMlKag\ny4iIiIiAikYqYuzDjPGciCgz5WZlHaGPGF9PoDGNUDFmSlPIeRoiUehY9ywtS8KXf3j9frQsWUHH\nuhfJ5+qXS+T1REUjBYVCIbpvF1GOHxQLe7W3sW3nhJoHtPO5Y1m25sr+M3WtiG5vI8bXE5TGNGLb\n24ixrWLMlCZ1T4mISDAVjRTE+K0iyvGDGDNFtpcBcb6eQGMaoWLMlKbMioaZjTazR8zszmR6ipkt\nNbOnzexeM1MvtIhIZLLc0/g48ASls8sBLgOWuvtMSmeiX5ZVsFrFeFx2rGMasdF5GuF0nkaYGDOl\nKZOiYWYHA2cC/8rua1qdA9yc/H4z0JxBNBERGUBWexrXAn8P7KqYN9Xd1ye/rwemNjzVEMXYhxnl\n+EGMmTSmEUxjGmFizJSmhhcNMzsLeMHdH6GfK+e6u7O720pERCKRxXkaJwHnmNmZwDjgT5J7d6w3\ns2nu3mlm04EXqq3c0tJCPvnGk8vlmDVrVk9lL/clNnq6PK/e2yuPCZS/sQ80XSwW2Lp1wx7nRoSs\nv3Xrhp6/KXR7ocsvuukSJu5zCLmJx7Bx/XqWLLoKgNzEYwDo2vxY1enulydDLsfW7V17nFdRHo/o\nb/rV7b+j2LV7Z7ba8p2bVzPn4Pft8Xj5u1S5D7/8DXuw6Q1bt+5xLkPo+mW1vp5a3vc+2LyZ/LRp\npfydnaW/b6DpiRNpX7y46vMNNr1w+XJmTZtW099XzjCU7YVMr1ixgtbW1ro9/1Cmy/OyzFMoFGhv\nbwfo+bxMi5W+1GfDzE4FPunuZ5vZNcBL7v4lM7sMyLn7Zb2W9yzz9qcRJ/O0tLSRz7cFL18sFli2\nbCELFtRwCjWwaFFz3dZZsugqmg8+pbTOqitZcOzngp7/1lWrOO/YY2taJ3S9aif33bpqFXMO/SXt\nzbV1XTUvWsSSBQtqWgegrVikLXmDQ/jrqa2lhbYaPxB6byt4vZYWmqi9i2qo2wsV44l0MWYyM9w9\nlXsixXCeRrkKfBF4p5k9DcxLpoeF2F4gEOf4QXkPIiYa0winMY0wMWZKU6aXEXH3+4H7k983Au/I\nMo+IiAxM155KQa27o62tbXR11baNjo4V1PJFL8ZzIro2Pwa5U7KOsQddeyqcrj0VJsZMaVLRyEBX\nFzWNTwAsW6bTVkQkezGMaQx7MX6r0JhGmNj2MiDO1xNoTCNUjJnSpKIhIiLB1D2Vghj7MDWmEeb1\nNqaxvKODtpaWmtdb0dFBgfj2NmJ878WYKU0qGiKvI+O2bav53A6A5mXL0g8jw5K6p1IQ47cKjWmE\niW0vA+J8PUF8exkQZ1vFmClNKhoiIhJMRSMFMV4/P9oxjcjofhrhdD+NMDFmSpOKhoiIBFPRSEGM\nfZga0wijMY1wGtMIE2OmNKloiIhIMBWNFMTYh6kxjTAa0winMY0wMWZKk87TEKmiY92ztNR2WxEe\nfXH7kLbV+4S7YmcnhYB7UKzo6KCmq1iKpEBFIwUx9mHm800sW7Yw6xh7GE5jGtt2TiCfa63puX65\n66NDytDnhLvAQtDoE+40phEmxkxpUveUiIgEU9FIQYx9mBrTCBPlmEaEYwcQZ64Y33sxZkqTioaI\niART0UhBjH2YOk8jTJTnaUQ4dgBx5orxvRdjpjSpaIiISDAVjRTE2IepMY0wGtMIF2OuGN97MWZK\nk4qGiIgE03kaKYixD1PnaYTRmEa4oeQa6p0CyeVoWzj46zfG916MmdKkoiEidTPUOwW2RdgVJiXq\nnkpBjH2YGtMIozGNcDHmivG9F2OmNKloiIhIMBWNFMTYh6nzNMJoTCNcjLlifO/FmClNKhoiIhJM\nRSMFMfZhakwjjMY0wsWYK8b3XoyZ0qSiISIiwVQ0UhBjH6bGNMJoTCNcjLlifO/FmClNKhoiIhJM\nRSMFMfZhakwjjMY0wsWYK8b3XoyZ0qSiISIiwVQ0UhBjH6bGNMJoTCNcjLlifO/FmClNKhoiIhKs\n4UXDzA4xs/vM7HEze8zMPpbMn2JmS83saTO718xyjc42VDH2YWpMI4zGNMLFmCvG916MmdKUxZ7G\nduBv3f1NwBzgI2b2RuAyYKm7zwR+kUyLiEhEGl403L3T3Vckv28GngQOAs4Bbk4WuxlobnS2oYqx\nD1NjGmE0phEuxlwxvvdizJSmTMc0zCwPzAZ+DUx19/XJQ+uBqRnFEhGRfmR2EyYzmwj8EPi4u79i\nZj2PububmVdbr6WlhXzyjSeXyzFr1qyeyl7uS2z0dHleLcvD7nGH8l5BmtPFYoGtWzdQLBZqWn/r\n1g015wtdfu2Ld1LkzT3f7svjCYNNl7/bbN3eRbFrRfD6r27/HcWuXbvzVVm+c/Nq5hz8vqrbC81X\nnu7esZlCsdjzjbw8BjDYdFnldFM+P+j6G7ZurXl7G7Zu7bO90PUXLl/OrGnTGrK95R0dtMyfD0B+\n2jQAip2dfaY7N25kztFH90w/sXo1Z55ySr/L9ze9fOVKpk2dGrx8z/TEibQvXlzKP8TPg3pMFwoF\n2tvbS3lT3kM096qfzXVlZvsAdwE/dfeFybyngCZ37zSz6cB97n5Ur/W8XnlfeeUVhvLcEyZM4MEH\nH6xpl7SlpY18vq2m7Sxa1MyCBUuCly8WCyxbtrCmdYaynVrWWbLoKpoPLr2hF626kgXHfi7o+W9d\ntYrzjj22pnVC16ssQpXr7WBxTdsC+M5/fpQ1f/femtYBaF60iCULFvRMVxaCWtYbyrZqWa/1lFNq\n7qLam+2FrNe7req9vd7aikXakg/nnkyFQnRdVGaGu9vgSw6u4XsaVtqluBF4olwwEj8GLgS+lPxb\n2yfXXvrCF26gs9MYNSq8x2706M189rMfiu4FArpHeCiNaYSLMVeUmSL8PEhTFt1TJwMLgFVm9kgy\n73Lgi8BtZnYxUATObWSoLVtg+vRLGTt2YvA6a9f+Sx0TiYjEJ4ujp5a5+yh3n+Xus5Ofe9x9o7u/\nw91nuvu73L2r0dmGKsbjsnWeRhidpxEuxlxRZorw8yBNOiNcRESCqWikIMY+TJ2nEUZjGuFizBVl\npgg/D9KkoiEiIsFUNFIQYx+mxjTCaEwjXIy5oswU4edBmjI7uW+kuPLKr/Lssy/S3l4IXqejYwUR\n7lWLiAxKRWMvvfyyMWdOe03rLFtW/8tq6TyNMBrTCBdjrigzjfAxDRUNkZRs6n6VliW1dXflxnXX\nKY1IfahopKDy+k6xiHZMI3dK1jH2UO0yIkO1y/cnn2utcft99wZDLyPSaDHmijJThJcRSZMGwkVE\nJJiKRgpi28uAODNpTCNMbN+cy2LMFWWmEbyXASoaIiJSAxWNFMQ4fhBjJp2nESbGcw8gzlxRZhrh\n52moaIiISDAdPZWCGMcPQs/TKNxzD3TvPuxz4/r1FJYE3Mpk3DiakjurhdKYRpgY++khzlxRZhrh\nYxoqGq933d005XI9k2v32WeP6f4UuobNletFJEXqnkpBjOMHMWbSmEaYGPvpIc5cUWbSmIaIiEiJ\nikYKYh3aWPdVAAAJpElEQVTTiI3GNMLE2E8PceaKMtMIH9NQ0RARkWAqGimIcfwgxkwa0wgTYz89\nxJkrykwa0xARESlR0UhBjOMHMWbSmEaYGPvpIc5cUWYa4WMaOk9DRGSIlnd00NbSUttKuRxtC+O6\nQVotVDRSoPtphBnp99NIS4z3iIA4c2Wdady2bbT12v5gmdoiHIephbqnREQkmIpGCmLby4A4M2lM\nI0xs3+bLYsylTI2n7imRDHWse5bN3fvVdG/x3LhuFs6fU8dUIv1T0UiBxjTCaEyjr207JzB+nwvJ\n544NzlTtvuKNkPX4QTXK1HjqnhIRkWAqGimIbS8D4sykMY0wMWaCOPvqlanx1D1VB1u2bGHNH/4A\nu3ZVfXzzH//IkytXVn1s8tSpTJs2rZ7xRESGTEUjBb3HNF577TVeefppDt1336rL79PdzeRnn+0z\nf9PWrfzq8ceZPH58n8cGvaNerzvp1XtMY+26dT15Qu/294dn7qNp9l/UNVetsh7TqGawTB3rnqVl\nCTy8PnwAfWXnMxw37fCa1uk94B5jX/1wzDSkEwIhmpMCVTTqZN8xY5g2cWJNj+3ctYvRW7bQNGNG\nn8cGu6Neo++kN2bnzp48oXf7+0M/e15Sm207J5DPtTJ+n1V7DKAPZNmaK2teJ6sB95Gu2gmBIWI5\nKVBFIwUxjh+E3iO8kcbvc2TWEfqIbS8D4slU3qOB0l5N+4ou2lcMvJdS3qMpC9mz2ZtDiGPby4A4\nM6VJRUNEqirv0QDBeyjlPZqykPW0RzO8RHX0lJnNN7OnzOx3ZvaprPOEivGciBgzvbr9d1lH6CPG\n+2nEmAnizBXl/TQizJSmaIqGmY0GrgfmA0cD55vZG7NNFaazM743U4yZuneszTpCH52bV2cdoY8Y\nM0GcuVZ0dmYdoY8YM6UpmqIBnACsdveiu28HbgXenXGmIN3djR2EDhFjpl10Zx2hj+4dm7OO0EeM\nmSDOXF3d8b2mYsyUppjGNA4CKo9DXQu8NaMsIjICtd6znK7ucX3mDzRgr2t97SmmouFZbnzsWHj+\n+dsZNWp08Dq7dm0EoKur2Oexzbt28ejLL1dd75Xt26s+1r19O5gFb38g1TJlbfvOl7KO0EdXd3xd\nCTFmgjhzFWs81Lyre9weA/VlAw3Y1zpQX2um4cbcM/2s7mFmc4A2d5+fTF8O7HL3L1UsE0dYEZFh\nxt1T+UYaU9EYA/wWOA14DugAznf3JzMNJiIiPaLpnnL3HWb2f4CfAaOBG1UwRETiEs2ehoiIxC/z\nQ27N7Dtmtt7MHq2Y12Zma83skeTnjIrHLk9O/nvKzN5VMf8tZvZo8tjX9jLTIWZ2n5k9bmaPmdnH\nkvlTzGypmT1tZveaWa5inbrmGiBTZm1lZuPM7NdmtiLJ1JbMz7Kd+suU6Wsqeb7RybbvTKYza6cB\nMsXQTkUzW5VsvyOZl2lb9ZMp68+pnJktNrMnzewJM3trQ9rJ3TP9AeYCs4FHK+Z9BvhElWWPBlYA\n+wB5YDW795Y6gBOS3+8G5u9FpmnArOT3iZTGWt4IXAP8QzL/U8AXG5VrgExZt9X45N8xwHJKh0ln\n1k4DZMq0nZLn+ATwPeDHyXSm7dRPphja6RlgSq95Wb+mqmXK+r13M/BXFa/1SY1op8z3NNz9QWBT\nlYeqjfS/G/i+u2939yKlP/ytZjYd2N/dO5LlbgGa9yJTp7uvSH7fDDxJ6TyScyj9R5H8W95G3XMN\nkAmybatXk1/HUnpBOhm20wCZIMN2MrODgTOBf63IkWk79ZPJyLCdKuP1ms60rfrJ1N+8umcys0nA\nXHf/DpTGhN39ZRrQTpkXjQF81MxWmtmNFbtYMyid9Fe2ltIHZ+/569j9gbpXzCxPaU/o18BUd1+f\nPLQemJpFropMy5NZmbWVmY0ysxWU2uPe5MWXaTv1kwmyfU1dC/w9UHl9+KxfT9UyOdm/9xz4uZn9\nxsw+lMzLuq2qZYLs2upw4EUzu8nMHjazb5vZBBrQTrEWjW9RapRZwPPAV7IIYWYTgR8CH3f3Vyof\n89K+XMOPIkgyLU4ybSbjtnL3Xe4+CziY0jeXY3o93vB2qpLpTWTYTmZ2FvCCuz9C9W+mDW+nATLF\n8N472d1nA2cAHzGzuZUPZvTeq5Ypy7YaAxwPfNPdjwe2AJdVLlCvdoqyaLj7C56gtOt8QvLQOuCQ\nikUPplQl1yW/V85ftzcZzGwfSgXju+5evi3dejObljw+HXihkbkqMi0qZ4qhrZIcLwP3AaeTcTtV\nyTQ/43Y6CTjHzJ4Bvg/MM7Pvkm07Vct0SwyvJ3d/Pvn3ReD2JEOmr6lqmTJuq7XAWnd/KJleTKmI\ndNa9nQYa8GjUD6WBmcqB8OkVv/8t8G++52DOWEoV/vfsHsz5NaUBT2PvB5iMUt/etb3mXwN8Kvn9\nMvoOMtUt1wCZMmsr4A1ALvl9P+ABSn3kWbZTf5mmZfmaqtj2qcCdWb+eBsiU9XtvPKU+doAJwL8D\n78r4NdVfpkxfU8lre2bye1vSRnVvp716saXxQ+lbznPANkoXLPwrSh+Oq4CVwBJK/XTl5a+gNIjz\nFHB6xfy3AI8mj319LzOdQqmfdwXwSPIzH5gC/Bx4GriX5MOpEbn6yXRGlm0FvBl4ONn2o8Cnk/lZ\ntlN/mTJ9TVU856nsPlIps3bqlampItN3M37vHZ68xlcAjwGXZ91WA2TK+nPqOOChZPs/onT0VN3b\nSSf3iYhIsCjHNEREJE4qGiIiEkxFQ0REgqloiIhIMBUNEREJpqIhIiLBVDREApjZP1rpUusrk8tg\nn5Bc7+eNWWcTaSSdpyEyCDM7kdJ1hU519+1mNgXY15NLS4i8nmhPQ2Rw04AN7r4dwN03uvvzZlZI\nbmBzdsWNeH5rZn+AnpvbFJIro95TviaQyHCmoiEyuHuBQ5KC8A0ze1sy3yldTPROd5/tpaugrgC+\nbGZjgOuA97r7nwE3Af+USXqRFI3JOoBI7Nx9i5m9hdJdJt8O/MDMypeh7rmsuJn9A/Cqu38ruUT8\nmyjdgwFgNKVrrIkMayoaIgHcfRdwP3C/le5nf2H5IQAzewfwXqC8F2LA4+5+UqOzitSTuqdEBmFm\nM83syIpZs4H/qnj8MOAbwLnu/loy+7fAgWY2J1lmHzM7ulGZRepFexoig5sIXJfcznMH8DvgEko3\nvjFKex1TgCVJV9Q6dz/LzN4HfD25n/MYSrdXfSKD/CKp0SG3IiISTN1TIiISTEVDRESCqWiIiEgw\nFQ0REQmmoiEiIsFUNEREJJiKhoiIBFPREBGRYP8fUB+PwnYBMHYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f5a90d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmpp_area=np.sum(lmpp != 0, axis=(0,1))\n",
    "prob_area=np.sum(prob_dat != 0, axis=(0,1))\n",
    "\n",
    "lmpp_mean=np.sum(lmpp , axis=(0,1))/lmpp_area\n",
    "prob_mean=np.sum(prob_dat , axis=(0,1))/prob_area\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "#ax2 = fig.add_subplot(212)\n",
    "\n",
    "ax1.hist(lmpp_area,bins=20, color='red',alpha=0.5, label=\"LMPP\")\n",
    "ax1.hist(prob_area,bins=20, color='blue',alpha=0.5, label=\"ProB\" )\n",
    "ax1.set_title('Cell size(pixcel)')\n",
    "ax1.set_xlabel('Size')\n",
    "ax1.set_ylabel('freq')\n",
    "ax1.grid(True)\n",
    "ax1.legend(loc=\"upper right\")\n",
    "\n",
    "#ax2.hist(lmpp_mean,bins=20, color='red',alpha=0.5, label=\"LMPP\")\n",
    "#ax2.hist(prob_mean,bins=20, color='blue',alpha=0.5, label=\"ProB\" )\n",
    "#ax2.set_title('average blightness')\n",
    "#ax2.set_xlabel('mean')\n",
    "#ax2.set_ylabel('freq')\n",
    "#ax2.grid(True)\n",
    "#ax2.legend(loc=\"upper right\")\n",
    "\n",
    "fig.show()\n",
    "#plt.savefig('cellsize.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "area = np.r_[lmpp_area, prob_area]\n",
    "mean = np.r_[lmpp_mean, prob_mean]\n",
    "shuffle = np.random.permutation(len(t_data))\n",
    "data = np.vstack((area,mean)).transpose(1,0)\n",
    "\n",
    "data = np.asarray(data[shuffle]) \n",
    "area = np.asarray(area[shuffle]) \n",
    "label = np.asarray(t_data[shuffle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-th cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size [ 0.81623932  0.75641026  0.76923077  0.77777778  0.85775862]\n",
      "size 0.79548334807\n",
      "size and mean [ 0.82051282  0.75641026  0.77350427  0.79487179  0.83189655]\n",
      "size and mean 0.795439139405\n"
     ]
    }
   ],
   "source": [
    "scores_area = cross_val_score(linear_model.LogisticRegression(), area[:, np.newaxis], label, cv=5)\n",
    "scores_area_mean = cross_val_score(linear_model.LogisticRegression(), data, label, cv=5)\n",
    "print \"size\", scores_area\n",
    "print \"size\", np.mean(scores_area)\n",
    "print \"size and mean\", scores_area_mean\n",
    "print \"size and mean\", np.mean(scores_area_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Classification using Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch =60\n",
    "batchsize=40\n",
    "gpu_flag = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Learning loop(cross valilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.asarray(x_data[shuffle,:,:,:])\n",
    "t_data = np.asarray(t_data[shuffle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch:  1\n",
      "train mean loss=inf, accuracy=0.622459891008\n",
      "test mean loss=inf, accuracy=0.716738191797\n",
      "epoch:  2\n",
      "train mean loss=inf, accuracy=0.739037432454\n",
      "test mean loss=inf, accuracy=0.66952789367\n",
      "epoch:  3\n",
      "train mean loss=inf, accuracy=0.727272731735\n",
      "test mean loss=inf, accuracy=0.759656663616\n",
      "epoch:  4\n",
      "train mean loss=inf, accuracy=0.802139037433\n",
      "test mean loss=inf, accuracy=0.733905577864\n",
      "epoch:  5\n",
      "train mean loss=inf, accuracy=0.790374331296\n",
      "test mean loss=inf, accuracy=0.708154508996\n",
      "epoch:  6\n",
      "train mean loss=inf, accuracy=0.807486633247\n",
      "test mean loss=inf, accuracy=0.738197419265\n",
      "epoch:  7\n",
      "train mean loss=inf, accuracy=0.836363633367\n",
      "test mean loss=inf, accuracy=0.763948496575\n",
      "epoch:  8\n",
      "train mean loss=inf, accuracy=0.849197863258\n",
      "test mean loss=inf, accuracy=0.738197417474\n",
      "epoch:  9\n",
      "train mean loss=inf, accuracy=0.84598930188\n",
      "test mean loss=inf, accuracy=0.768240348208\n",
      "epoch:  10\n",
      "train mean loss=inf, accuracy=0.838502667804\n",
      "test mean loss=inf, accuracy=0.768240339766\n",
      "epoch:  11\n",
      "train mean loss=inf, accuracy=0.872727269157\n",
      "test mean loss=inf, accuracy=0.781115891084\n",
      "epoch:  12\n",
      "train mean loss=inf, accuracy=0.920855608853\n",
      "test mean loss=inf, accuracy=0.733905584515\n",
      "epoch:  13\n",
      "train mean loss=inf, accuracy=0.930481282466\n",
      "test mean loss=inf, accuracy=0.768240339766\n",
      "epoch:  14\n",
      "train mean loss=inf, accuracy=0.944385028778\n",
      "test mean loss=inf, accuracy=0.785407722252\n",
      "epoch:  15\n",
      "train mean loss=inf, accuracy=0.948663103708\n",
      "test mean loss=inf, accuracy=0.798283266919\n",
      "epoch:  16\n",
      "train mean loss=inf, accuracy=0.967914447746\n",
      "test mean loss=inf, accuracy=0.781115884433\n",
      "epoch:  17\n",
      "train mean loss=inf, accuracy=0.958288779233\n",
      "test mean loss=inf, accuracy=0.781115891084\n",
      "epoch:  18\n",
      "train mean loss=inf, accuracy=0.964705889556\n",
      "test mean loss=inf, accuracy=0.781115882642\n",
      "epoch:  19\n",
      "train mean loss=inf, accuracy=0.935828870949\n",
      "test mean loss=inf, accuracy=0.768240339766\n",
      "epoch:  20\n",
      "train mean loss=inf, accuracy=0.959358292467\n",
      "test mean loss=inf, accuracy=0.75107296035\n",
      "epoch:  21\n",
      "train mean loss=inf, accuracy=0.946524065765\n",
      "test mean loss=inf, accuracy=0.768240348208\n",
      "epoch:  22\n",
      "train mean loss=0.923308997649, accuracy=0.971123009442\n",
      "test mean loss=inf, accuracy=0.781115882642\n",
      "epoch:  23\n",
      "train mean loss=inf, accuracy=0.986096268988\n",
      "test mean loss=inf, accuracy=0.763948506808\n",
      "epoch:  24\n",
      "train mean loss=0.989300558622, accuracy=0.970053481546\n",
      "test mean loss=inf, accuracy=0.76824035665\n",
      "epoch:  25\n",
      "train mean loss=inf, accuracy=0.96363636421\n",
      "test mean loss=inf, accuracy=0.785407724043\n",
      "epoch:  26\n",
      "train mean loss=0.289493147061, accuracy=0.988235300237\n",
      "test mean loss=inf, accuracy=0.772532198051\n",
      "epoch:  27\n",
      "train mean loss=0.312338910474, accuracy=0.990374338181\n",
      "test mean loss=inf, accuracy=0.751072963932\n",
      "epoch:  28\n",
      "train mean loss=inf, accuracy=0.975401073216\n",
      "test mean loss=inf, accuracy=0.789699584118\n",
      "epoch:  29\n",
      "train mean loss=inf, accuracy=0.90053475955\n",
      "test mean loss=inf, accuracy=0.78111587241\n",
      "epoch:  30\n",
      "train mean loss=inf, accuracy=0.937967912399\n",
      "test mean loss=inf, accuracy=0.806866959952\n",
      "epoch:  31\n",
      "train mean loss=inf, accuracy=0.958288771583\n",
      "test mean loss=inf, accuracy=0.746781122531\n",
      "epoch:  32\n",
      "train mean loss=inf, accuracy=0.926203215186\n",
      "test mean loss=inf, accuracy=0.789699573885\n",
      "epoch:  33\n",
      "train mean loss=inf, accuracy=0.957219253887\n",
      "test mean loss=inf, accuracy=0.79828326871\n",
      "epoch:  34\n",
      "train mean loss=inf, accuracy=0.983957226901\n",
      "test mean loss=inf, accuracy=0.806866951511\n",
      "epoch:  35\n",
      "train mean loss=0.29754076107, accuracy=0.989304817934\n",
      "test mean loss=inf, accuracy=0.79828326871\n",
      "epoch:  36\n",
      "train mean loss=0.0991559148617, accuracy=0.994652408967\n",
      "test mean loss=inf, accuracy=0.781115892875\n",
      "epoch:  37\n",
      "train mean loss=0.0965650932102, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.781115892875\n",
      "epoch:  38\n",
      "train mean loss=inf, accuracy=0.973262037185\n",
      "test mean loss=inf, accuracy=0.798283256686\n",
      "epoch:  39\n",
      "train mean loss=inf, accuracy=0.985026744279\n",
      "test mean loss=inf, accuracy=0.793991417076\n",
      "epoch:  40\n",
      "train mean loss=inf, accuracy=0.964705887963\n",
      "test mean loss=inf, accuracy=0.772532198051\n",
      "epoch:  41\n",
      "train mean loss=0.223025226437, accuracy=0.99358289127\n",
      "test mean loss=inf, accuracy=0.811158809795\n",
      "epoch:  42\n",
      "train mean loss=0.127484920125, accuracy=0.99679144436\n",
      "test mean loss=inf, accuracy=0.824034344229\n",
      "epoch:  43\n",
      "train mean loss=0.256658399112, accuracy=0.994652408967\n",
      "test mean loss=inf, accuracy=0.798283265128\n",
      "epoch:  44\n",
      "train mean loss=inf, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.81115878933\n",
      "epoch:  45\n",
      "train mean loss=0.0983299088351, accuracy=0.995721926664\n",
      "test mean loss=inf, accuracy=0.815450640963\n",
      "epoch:  46\n",
      "train mean loss=0.0245427021191, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  47\n",
      "train mean loss=0.091237708209, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.811158799562\n",
      "epoch:  48\n",
      "train mean loss=0.0147535648337, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.811158799562\n",
      "epoch:  49\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742492596\n",
      "epoch:  50\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  51\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  52\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  53\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  54\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  55\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  56\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  57\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  58\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  59\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  60\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "1\n",
      "epoch:  1\n",
      "train mean loss=inf, accuracy=0.603208558445\n",
      "test mean loss=inf, accuracy=0.742489277549\n",
      "epoch:  2\n",
      "train mean loss=inf, accuracy=0.768983958877\n",
      "test mean loss=inf, accuracy=0.708154507205\n",
      "epoch:  3\n",
      "train mean loss=inf, accuracy=0.778609616234\n",
      "test mean loss=inf, accuracy=0.660944202427\n",
      "epoch:  4\n",
      "train mean loss=inf, accuracy=0.797860962822\n",
      "test mean loss=inf, accuracy=0.759656651593\n",
      "epoch:  5\n",
      "train mean loss=inf, accuracy=0.814973256486\n",
      "test mean loss=inf, accuracy=0.712446348606\n",
      "epoch:  6\n",
      "train mean loss=inf, accuracy=0.860962564932\n",
      "test mean loss=inf, accuracy=0.768240334394\n",
      "epoch:  7\n",
      "train mean loss=inf, accuracy=0.877005350781\n",
      "test mean loss=inf, accuracy=0.74678111895\n",
      "epoch:  8\n",
      "train mean loss=inf, accuracy=0.899465242172\n",
      "test mean loss=inf, accuracy=0.742489269107\n",
      "epoch:  9\n",
      "train mean loss=inf, accuracy=0.88770053954\n",
      "test mean loss=inf, accuracy=0.712446348606\n",
      "epoch:  10\n",
      "train mean loss=inf, accuracy=0.899465244722\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  11\n",
      "train mean loss=inf, accuracy=0.930481287566\n",
      "test mean loss=inf, accuracy=0.74678111895\n",
      "epoch:  12\n",
      "train mean loss=inf, accuracy=0.963636372816\n",
      "test mean loss=inf, accuracy=0.763948505017\n",
      "epoch:  13\n",
      "train mean loss=inf, accuracy=0.967914440096\n",
      "test mean loss=inf, accuracy=0.712446338373\n",
      "epoch:  14\n",
      "train mean loss=inf, accuracy=0.955080221044\n",
      "test mean loss=inf, accuracy=0.74248927934\n",
      "epoch:  15\n",
      "train mean loss=inf, accuracy=0.971122998286\n",
      "test mean loss=inf, accuracy=0.733905586306\n",
      "epoch:  16\n",
      "train mean loss=inf, accuracy=0.980748670305\n",
      "test mean loss=inf, accuracy=0.751072962141\n",
      "epoch:  17\n",
      "train mean loss=1.07896841129, accuracy=0.965775403109\n",
      "test mean loss=inf, accuracy=0.725321893272\n",
      "epoch:  18\n",
      "train mean loss=inf, accuracy=0.95721925803\n",
      "test mean loss=inf, accuracy=0.725321893272\n",
      "epoch:  19\n",
      "train mean loss=inf, accuracy=0.964705885413\n",
      "test mean loss=inf, accuracy=0.763948494784\n",
      "epoch:  20\n",
      "train mean loss=inf, accuracy=0.961497337423\n",
      "test mean loss=inf, accuracy=0.708154507205\n",
      "epoch:  21\n",
      "train mean loss=0.67560418746, accuracy=0.977540114665\n",
      "test mean loss=inf, accuracy=0.738197427707\n",
      "epoch:  22\n",
      "train mean loss=0.416514136321, accuracy=0.982887706655\n",
      "test mean loss=inf, accuracy=0.721030051872\n",
      "epoch:  23\n",
      "train mean loss=inf, accuracy=0.979679151015\n",
      "test mean loss=inf, accuracy=0.776824031009\n",
      "epoch:  24\n",
      "train mean loss=inf, accuracy=0.971122999242\n",
      "test mean loss=inf, accuracy=0.772532189609\n",
      "epoch:  25\n",
      "train mean loss=0.261329153823, accuracy=0.990374338181\n",
      "test mean loss=inf, accuracy=0.768240348208\n",
      "epoch:  26\n",
      "train mean loss=0.0675510192143, accuracy=0.99679144691\n",
      "test mean loss=inf, accuracy=0.785407732485\n",
      "epoch:  27\n",
      "train mean loss=0.0820765294293, accuracy=0.99679144691\n",
      "test mean loss=inf, accuracy=0.798283266919\n",
      "epoch:  28\n",
      "train mean loss=inf, accuracy=0.979679152609\n",
      "test mean loss=inf, accuracy=0.703862665805\n",
      "epoch:  29\n",
      "train mean loss=inf, accuracy=0.964705890513\n",
      "test mean loss=inf, accuracy=0.733905586306\n",
      "epoch:  30\n",
      "train mean loss=inf, accuracy=0.952941179594\n",
      "test mean loss=inf, accuracy=0.759656644942\n",
      "epoch:  31\n",
      "train mean loss=0.460705046412, accuracy=0.979679153565\n",
      "test mean loss=inf, accuracy=0.776824041242\n",
      "epoch:  32\n",
      "train mean loss=0.246309328044, accuracy=0.989304823034\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  33\n",
      "train mean loss=0.162708089774, accuracy=0.99358289127\n",
      "test mean loss=inf, accuracy=0.789699584118\n",
      "epoch:  34\n",
      "train mean loss=0.261495526812, accuracy=0.991443855877\n",
      "test mean loss=inf, accuracy=0.776824031009\n",
      "epoch:  35\n",
      "train mean loss=inf, accuracy=0.980748663612\n",
      "test mean loss=inf, accuracy=0.789699575676\n",
      "epoch:  36\n",
      "train mean loss=inf, accuracy=0.987165782541\n",
      "test mean loss=inf, accuracy=0.772532198051\n",
      "epoch:  37\n",
      "train mean loss=0.111004599943, accuracy=0.994652411517\n",
      "test mean loss=inf, accuracy=0.776824049684\n",
      "epoch:  38\n",
      "train mean loss=0.0777256123865, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.776824041242\n",
      "epoch:  39\n",
      "train mean loss=0.0136065448033, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.772532189609\n",
      "epoch:  40\n",
      "train mean loss=0.163344491054, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.785407732485\n",
      "epoch:  41\n",
      "train mean loss=0.00174999127881, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.776824039451\n",
      "epoch:  42\n",
      "train mean loss=0.0924688010292, accuracy=0.992513371024\n",
      "test mean loss=inf, accuracy=0.776824039451\n",
      "epoch:  43\n",
      "train mean loss=inf, accuracy=0.975401077678\n",
      "test mean loss=inf, accuracy=0.781115889293\n",
      "epoch:  44\n",
      "train mean loss=inf, accuracy=0.981818186408\n",
      "test mean loss=inf, accuracy=0.78969955342\n",
      "epoch:  45\n",
      "train mean loss=0.106797799632, accuracy=0.99679144691\n",
      "test mean loss=inf, accuracy=0.776824039451\n",
      "epoch:  46\n",
      "train mean loss=0.140780251294, accuracy=0.991443851415\n",
      "test mean loss=inf, accuracy=0.785407732485\n",
      "epoch:  47\n",
      "train mean loss=inf, accuracy=0.948663106258\n",
      "test mean loss=inf, accuracy=0.763948503226\n",
      "epoch:  48\n",
      "train mean loss=inf, accuracy=0.917647054807\n",
      "test mean loss=inf, accuracy=0.763948503226\n",
      "epoch:  49\n",
      "train mean loss=inf, accuracy=0.910160434437\n",
      "test mean loss=inf, accuracy=0.742489267316\n",
      "epoch:  50\n",
      "train mean loss=inf, accuracy=0.942245980635\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  51\n",
      "train mean loss=inf, accuracy=0.971122999242\n",
      "test mean loss=inf, accuracy=0.776824039451\n",
      "epoch:  52\n",
      "train mean loss=inf, accuracy=0.986096264844\n",
      "test mean loss=inf, accuracy=0.759656665407\n",
      "epoch:  53\n",
      "train mean loss=inf, accuracy=0.99358289382\n",
      "test mean loss=inf, accuracy=0.738197427707\n",
      "epoch:  54\n",
      "train mean loss=0.106973546, accuracy=0.99358289127\n",
      "test mean loss=inf, accuracy=0.74248927934\n",
      "epoch:  55\n",
      "train mean loss=0.158785512099, accuracy=0.991443853327\n",
      "test mean loss=inf, accuracy=0.746781112298\n",
      "epoch:  56\n",
      "train mean loss=inf, accuracy=0.967914443603\n",
      "test mean loss=inf, accuracy=0.763948503226\n",
      "epoch:  57\n",
      "train mean loss=inf, accuracy=0.977540112115\n",
      "test mean loss=inf, accuracy=0.776824049684\n",
      "epoch:  58\n",
      "train mean loss=0.380539922461, accuracy=0.988235297688\n",
      "test mean loss=inf, accuracy=0.772532187818\n",
      "epoch:  59\n",
      "train mean loss=inf, accuracy=0.99358289382\n",
      "test mean loss=inf, accuracy=0.768240354859\n",
      "epoch:  60\n",
      "train mean loss=inf, accuracy=0.990374335631\n",
      "test mean loss=inf, accuracy=0.772532187818\n",
      "2\n",
      "epoch:  1\n",
      "train mean loss=inf, accuracy=0.680213901448\n",
      "test mean loss=inf, accuracy=0.69098713137\n",
      "epoch:  2\n",
      "train mean loss=inf, accuracy=0.740106956207\n",
      "test mean loss=inf, accuracy=0.618025747492\n",
      "epoch:  3\n",
      "train mean loss=inf, accuracy=0.766844924121\n",
      "test mean loss=inf, accuracy=0.630901280135\n",
      "epoch:  4\n",
      "train mean loss=inf, accuracy=0.749732618982\n",
      "test mean loss=inf, accuracy=0.721030050081\n",
      "epoch:  5\n",
      "train mean loss=inf, accuracy=0.803208557361\n",
      "test mean loss=inf, accuracy=0.746781108717\n",
      "epoch:  6\n",
      "train mean loss=inf, accuracy=0.834224598612\n",
      "test mean loss=inf, accuracy=0.742489267316\n",
      "epoch:  7\n",
      "train mean loss=inf, accuracy=0.879144384581\n",
      "test mean loss=inf, accuracy=0.742489275758\n",
      "epoch:  8\n",
      "train mean loss=inf, accuracy=0.863101597776\n",
      "test mean loss=inf, accuracy=0.673819745303\n",
      "epoch:  9\n",
      "train mean loss=inf, accuracy=0.871657754648\n",
      "test mean loss=inf, accuracy=0.742489265526\n",
      "epoch:  10\n",
      "train mean loss=inf, accuracy=0.901604275015\n",
      "test mean loss=inf, accuracy=0.733905574283\n",
      "epoch:  11\n",
      "train mean loss=inf, accuracy=0.928342253129\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  12\n",
      "train mean loss=inf, accuracy=0.936898401396\n",
      "test mean loss=inf, accuracy=0.768240336185\n",
      "epoch:  13\n",
      "train mean loss=inf, accuracy=0.921925135794\n",
      "test mean loss=inf, accuracy=0.759656643151\n",
      "epoch:  14\n",
      "train mean loss=inf, accuracy=0.954010700797\n",
      "test mean loss=inf, accuracy=0.781115879061\n",
      "epoch:  15\n",
      "train mean loss=inf, accuracy=0.947593584418\n",
      "test mean loss=inf, accuracy=0.768240336185\n",
      "epoch:  16\n",
      "train mean loss=inf, accuracy=0.968983964487\n",
      "test mean loss=inf, accuracy=0.682403428104\n",
      "epoch:  17\n",
      "train mean loss=inf, accuracy=0.935828877643\n",
      "test mean loss=inf, accuracy=0.725321881249\n",
      "epoch:  18\n",
      "train mean loss=inf, accuracy=0.949732628098\n",
      "test mean loss=inf, accuracy=0.763948494784\n",
      "epoch:  19\n",
      "train mean loss=inf, accuracy=0.954010698247\n",
      "test mean loss=inf, accuracy=0.759656634709\n",
      "epoch:  20\n",
      "train mean loss=inf, accuracy=0.936898397252\n",
      "test mean loss=inf, accuracy=0.755364810193\n",
      "epoch:  21\n",
      "train mean loss=inf, accuracy=0.949732617261\n",
      "test mean loss=inf, accuracy=0.793991413495\n",
      "epoch:  22\n",
      "train mean loss=inf, accuracy=0.987165782541\n",
      "test mean loss=inf, accuracy=0.781115868828\n",
      "epoch:  23\n",
      "train mean loss=inf, accuracy=0.986096267394\n",
      "test mean loss=inf, accuracy=0.802575116761\n",
      "epoch:  24\n",
      "train mean loss=0.272775854712, accuracy=0.989304815384\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  25\n",
      "train mean loss=inf, accuracy=0.987165774891\n",
      "test mean loss=inf, accuracy=0.759656651593\n",
      "epoch:  26\n",
      "train mean loss=inf, accuracy=0.983957221801\n",
      "test mean loss=inf, accuracy=0.759656651593\n",
      "epoch:  27\n",
      "train mean loss=inf, accuracy=0.961497329773\n",
      "test mean loss=inf, accuracy=0.815450651195\n",
      "epoch:  28\n",
      "train mean loss=0.0390169747169, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.77682403766\n",
      "epoch:  29\n",
      "train mean loss=0.000244040839016, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.77682403766\n",
      "epoch:  30\n",
      "train mean loss=0.0122517587029, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.798283265128\n",
      "epoch:  31\n",
      "train mean loss=0.011642452997, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.751072968792\n",
      "epoch:  32\n",
      "train mean loss=0.685347964885, accuracy=0.981818183858\n",
      "test mean loss=inf, accuracy=0.716738198448\n",
      "epoch:  33\n",
      "train mean loss=inf, accuracy=0.955080213394\n",
      "test mean loss=inf, accuracy=0.793991413495\n",
      "epoch:  34\n",
      "train mean loss=0.365682973303, accuracy=0.989304817934\n",
      "test mean loss=inf, accuracy=0.806866947929\n",
      "epoch:  35\n",
      "train mean loss=inf, accuracy=0.967914440096\n",
      "test mean loss=inf, accuracy=0.789699561862\n",
      "epoch:  36\n",
      "train mean loss=inf, accuracy=0.981818185452\n",
      "test mean loss=inf, accuracy=0.802575104738\n",
      "epoch:  37\n",
      "train mean loss=inf, accuracy=0.983957224351\n",
      "test mean loss=inf, accuracy=0.789699582327\n",
      "epoch:  38\n",
      "train mean loss=inf, accuracy=0.975401077678\n",
      "test mean loss=inf, accuracy=0.802575114971\n",
      "epoch:  39\n",
      "train mean loss=inf, accuracy=0.983957224351\n",
      "test mean loss=inf, accuracy=0.802575114971\n",
      "epoch:  40\n",
      "train mean loss=0.120318081232, accuracy=0.994652411517\n",
      "test mean loss=inf, accuracy=0.755364801751\n",
      "epoch:  41\n",
      "train mean loss=inf, accuracy=0.994652410561\n",
      "test mean loss=inf, accuracy=0.781115889293\n",
      "epoch:  42\n",
      "train mean loss=inf, accuracy=0.994652408967\n",
      "test mean loss=inf, accuracy=0.793991413495\n",
      "epoch:  43\n",
      "train mean loss=inf, accuracy=0.971122999242\n",
      "test mean loss=inf, accuracy=0.798283265128\n",
      "epoch:  44\n",
      "train mean loss=inf, accuracy=0.990374335631\n",
      "test mean loss=inf, accuracy=0.824034344229\n",
      "epoch:  45\n",
      "train mean loss=inf, accuracy=0.982887708248\n",
      "test mean loss=inf, accuracy=0.763948492994\n",
      "epoch:  46\n",
      "train mean loss=inf, accuracy=0.968983956199\n",
      "test mean loss=inf, accuracy=0.798283254896\n",
      "epoch:  47\n",
      "train mean loss=inf, accuracy=0.95614973364\n",
      "test mean loss=inf, accuracy=0.845493569906\n",
      "epoch:  48\n",
      "train mean loss=inf, accuracy=0.986096262294\n",
      "test mean loss=inf, accuracy=0.789699573885\n",
      "epoch:  49\n",
      "train mean loss=inf, accuracy=0.989304817934\n",
      "test mean loss=inf, accuracy=0.798283265128\n",
      "epoch:  50\n",
      "train mean loss=0.188598529432, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.819742502829\n",
      "epoch:  51\n",
      "train mean loss=0.0392899009948, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  52\n",
      "train mean loss=0.0458362765491, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.82403434602\n",
      "epoch:  53\n",
      "train mean loss=0.0, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.82403434602\n",
      "epoch:  54\n",
      "train mean loss=3.88170004185e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  55\n",
      "train mean loss=3.73120055494e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  56\n",
      "train mean loss=2.97172034108e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  57\n",
      "train mean loss=1.96298974831e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  58\n",
      "train mean loss=1.68946296173e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  59\n",
      "train mean loss=1.40127910872e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "epoch:  60\n",
      "train mean loss=1.20236016661e-07, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.819742494387\n",
      "3\n",
      "epoch:  1\n",
      "train mean loss=inf, accuracy=0.64385026789\n",
      "test mean loss=inf, accuracy=0.733905582725\n",
      "epoch:  2\n",
      "train mean loss=inf, accuracy=0.764705882672\n",
      "test mean loss=inf, accuracy=0.686695288179\n",
      "epoch:  3\n",
      "train mean loss=inf, accuracy=0.757219254652\n",
      "test mean loss=inf, accuracy=0.703862655572\n",
      "epoch:  4\n",
      "train mean loss=inf, accuracy=0.792513375295\n",
      "test mean loss=inf, accuracy=0.708154505415\n",
      "epoch:  5\n",
      "train mean loss=inf, accuracy=0.835294119496\n",
      "test mean loss=inf, accuracy=0.729613732882\n",
      "epoch:  6\n",
      "train mean loss=inf, accuracy=0.844919785778\n",
      "test mean loss=inf, accuracy=0.738197425916\n",
      "epoch:  7\n",
      "train mean loss=inf, accuracy=0.837433157758\n",
      "test mean loss=inf, accuracy=0.751072968792\n",
      "epoch:  8\n",
      "train mean loss=inf, accuracy=0.870588232808\n",
      "test mean loss=inf, accuracy=0.733905584515\n",
      "epoch:  9\n",
      "train mean loss=inf, accuracy=0.8866310177\n",
      "test mean loss=inf, accuracy=0.699570822613\n",
      "epoch:  10\n",
      "train mean loss=inf, accuracy=0.88663101515\n",
      "test mean loss=inf, accuracy=0.768240353069\n",
      "epoch:  11\n",
      "train mean loss=inf, accuracy=0.931550802713\n",
      "test mean loss=inf, accuracy=0.742489285991\n",
      "epoch:  12\n",
      "train mean loss=inf, accuracy=0.937967914948\n",
      "test mean loss=inf, accuracy=0.755364801751\n",
      "epoch:  13\n",
      "train mean loss=inf, accuracy=0.945454545518\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  14\n",
      "train mean loss=inf, accuracy=0.942245993385\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  15\n",
      "train mean loss=inf, accuracy=0.945454548068\n",
      "test mean loss=inf, accuracy=0.763948492994\n",
      "epoch:  16\n",
      "train mean loss=inf, accuracy=0.955080220087\n",
      "test mean loss=inf, accuracy=0.729613734673\n",
      "epoch:  17\n",
      "train mean loss=inf, accuracy=0.964705884457\n",
      "test mean loss=inf, accuracy=0.746781117159\n",
      "epoch:  18\n",
      "train mean loss=inf, accuracy=0.971122996692\n",
      "test mean loss=inf, accuracy=0.776824039451\n",
      "epoch:  19\n",
      "train mean loss=inf, accuracy=0.972192515983\n",
      "test mean loss=inf, accuracy=0.789699573885\n",
      "epoch:  20\n",
      "train mean loss=inf, accuracy=0.947593581868\n",
      "test mean loss=inf, accuracy=0.759656653384\n",
      "epoch:  21\n",
      "train mean loss=inf, accuracy=0.975401080228\n",
      "test mean loss=inf, accuracy=0.755364801751\n",
      "epoch:  22\n",
      "train mean loss=inf, accuracy=0.983957226901\n",
      "test mean loss=inf, accuracy=0.77253219626\n",
      "epoch:  23\n",
      "train mean loss=inf, accuracy=0.97540107226\n",
      "test mean loss=inf, accuracy=0.785407730694\n",
      "epoch:  24\n",
      "train mean loss=inf, accuracy=0.957219256437\n",
      "test mean loss=inf, accuracy=0.781115870619\n",
      "epoch:  25\n",
      "train mean loss=0.660364258917, accuracy=0.979679151015\n",
      "test mean loss=inf, accuracy=0.785407730694\n",
      "epoch:  26\n",
      "train mean loss=inf, accuracy=0.980748662655\n",
      "test mean loss=inf, accuracy=0.768240334394\n",
      "epoch:  27\n",
      "train mean loss=inf, accuracy=0.970053478996\n",
      "test mean loss=inf, accuracy=0.77682403766\n",
      "epoch:  28\n",
      "train mean loss=inf, accuracy=0.970053481546\n",
      "test mean loss=inf, accuracy=0.793991421937\n",
      "epoch:  29\n",
      "train mean loss=inf, accuracy=0.986096258788\n",
      "test mean loss=inf, accuracy=0.755364801751\n",
      "epoch:  30\n",
      "train mean loss=0.172066713969, accuracy=0.99358289382\n",
      "test mean loss=inf, accuracy=0.751072950118\n",
      "epoch:  31\n",
      "train mean loss=0.367434724164, accuracy=0.987165779991\n",
      "test mean loss=inf, accuracy=0.785407730694\n",
      "epoch:  32\n",
      "train mean loss=inf, accuracy=0.966844925906\n",
      "test mean loss=inf, accuracy=0.733905582725\n",
      "epoch:  33\n",
      "train mean loss=inf, accuracy=0.939037437745\n",
      "test mean loss=inf, accuracy=0.789699570304\n",
      "epoch:  34\n",
      "train mean loss=inf, accuracy=0.977540112115\n",
      "test mean loss=inf, accuracy=0.77682403587\n",
      "epoch:  35\n",
      "train mean loss=inf, accuracy=0.985026742048\n",
      "test mean loss=inf, accuracy=0.77682403766\n",
      "epoch:  36\n",
      "train mean loss=inf, accuracy=0.981818181308\n",
      "test mean loss=inf, accuracy=0.759656641361\n",
      "epoch:  37\n",
      "train mean loss=0.172042285555, accuracy=0.989304820484\n",
      "test mean loss=inf, accuracy=0.77253219626\n",
      "epoch:  38\n",
      "train mean loss=inf, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.785407730694\n",
      "epoch:  39\n",
      "train mean loss=0.138922627665, accuracy=0.99679144691\n",
      "test mean loss=inf, accuracy=0.793991413495\n",
      "epoch:  40\n",
      "train mean loss=0.0108614746844, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.793991413495\n",
      "epoch:  41\n",
      "train mean loss=inf, accuracy=0.985026736948\n",
      "test mean loss=inf, accuracy=0.798283265128\n",
      "epoch:  42\n",
      "train mean loss=0.628055755631, accuracy=0.983957226901\n",
      "test mean loss=inf, accuracy=0.789699570304\n",
      "epoch:  43\n",
      "train mean loss=inf, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.755364810193\n",
      "epoch:  44\n",
      "train mean loss=0.310247451533, accuracy=0.986096258788\n",
      "test mean loss=inf, accuracy=0.738197425916\n",
      "epoch:  45\n",
      "train mean loss=inf, accuracy=0.960427805064\n",
      "test mean loss=inf, accuracy=0.77682403587\n",
      "epoch:  46\n",
      "train mean loss=inf, accuracy=0.970053486646\n",
      "test mean loss=inf, accuracy=0.738197424125\n",
      "epoch:  47\n",
      "train mean loss=inf, accuracy=0.971122999242\n",
      "test mean loss=inf, accuracy=0.772532206492\n",
      "epoch:  48\n",
      "train mean loss=inf, accuracy=0.975401072579\n",
      "test mean loss=inf, accuracy=0.785407730694\n",
      "epoch:  49\n",
      "train mean loss=inf, accuracy=0.980748666162\n",
      "test mean loss=inf, accuracy=0.802575114971\n",
      "epoch:  50\n",
      "train mean loss=0.215201054005, accuracy=0.992513373574\n",
      "test mean loss=inf, accuracy=0.759656643151\n",
      "epoch:  51\n",
      "train mean loss=0.383580421461, accuracy=0.988235302787\n",
      "test mean loss=inf, accuracy=0.768240334394\n",
      "epoch:  52\n",
      "train mean loss=inf, accuracy=0.976470591869\n",
      "test mean loss=inf, accuracy=0.776824039451\n",
      "epoch:  53\n",
      "train mean loss=inf, accuracy=0.982887707292\n",
      "test mean loss=inf, accuracy=0.738197436149\n",
      "epoch:  54\n",
      "train mean loss=inf, accuracy=0.939037434239\n",
      "test mean loss=inf, accuracy=0.781115868828\n",
      "epoch:  55\n",
      "train mean loss=inf, accuracy=0.960427809527\n",
      "test mean loss=inf, accuracy=0.80686694972\n",
      "epoch:  56\n",
      "train mean loss=inf, accuracy=0.935828879237\n",
      "test mean loss=inf, accuracy=0.77253219626\n",
      "epoch:  57\n",
      "train mean loss=inf, accuracy=0.961497329773\n",
      "test mean loss=inf, accuracy=0.733905591167\n",
      "epoch:  58\n",
      "train mean loss=inf, accuracy=0.976470592825\n",
      "test mean loss=inf, accuracy=0.746781117159\n",
      "epoch:  59\n",
      "train mean loss=inf, accuracy=0.988235300237\n",
      "test mean loss=inf, accuracy=0.763948501435\n",
      "epoch:  60\n",
      "train mean loss=inf, accuracy=0.985026742048\n",
      "test mean loss=inf, accuracy=0.763948503226\n",
      "4\n",
      "epoch:  1\n",
      "train mean loss=inf, accuracy=0.593582887382\n",
      "test mean loss=inf, accuracy=0.755364816844\n",
      "epoch:  2\n",
      "train mean loss=inf, accuracy=0.742245984269\n",
      "test mean loss=inf, accuracy=0.755364808402\n",
      "epoch:  3\n",
      "train mean loss=inf, accuracy=0.782887700726\n",
      "test mean loss=inf, accuracy=0.742489267316\n",
      "epoch:  4\n",
      "train mean loss=inf, accuracy=0.802139034564\n",
      "test mean loss=inf, accuracy=0.755364801751\n",
      "epoch:  5\n",
      "train mean loss=inf, accuracy=0.820320850069\n",
      "test mean loss=inf, accuracy=0.746781115368\n",
      "epoch:  6\n",
      "train mean loss=inf, accuracy=0.842780751341\n",
      "test mean loss=inf, accuracy=0.738197424125\n",
      "epoch:  7\n",
      "train mean loss=inf, accuracy=0.883422461104\n",
      "test mean loss=inf, accuracy=0.721030036267\n",
      "epoch:  8\n",
      "train mean loss=inf, accuracy=0.869518712561\n",
      "test mean loss=inf, accuracy=0.738197425916\n",
      "epoch:  9\n",
      "train mean loss=inf, accuracy=0.89304812898\n",
      "test mean loss=inf, accuracy=0.721030056732\n",
      "epoch:  10\n",
      "train mean loss=inf, accuracy=0.889839569196\n",
      "test mean loss=inf, accuracy=0.755364816844\n",
      "epoch:  11\n",
      "train mean loss=inf, accuracy=0.929411760626\n",
      "test mean loss=inf, accuracy=0.746781106926\n",
      "epoch:  12\n",
      "train mean loss=inf, accuracy=0.955080223593\n",
      "test mean loss=inf, accuracy=0.751072967001\n",
      "epoch:  13\n",
      "train mean loss=inf, accuracy=0.960427814626\n",
      "test mean loss=inf, accuracy=0.768240342836\n",
      "epoch:  14\n",
      "train mean loss=0.675604957707, accuracy=0.979679153565\n",
      "test mean loss=inf, accuracy=0.742489265526\n",
      "epoch:  15\n",
      "train mean loss=0.538153150329, accuracy=0.975401074172\n",
      "test mean loss=inf, accuracy=0.75536479996\n",
      "epoch:  16\n",
      "train mean loss=1.32562470665, accuracy=0.958288777321\n",
      "test mean loss=inf, accuracy=0.7253218879\n",
      "epoch:  17\n",
      "train mean loss=inf, accuracy=0.931550801119\n",
      "test mean loss=inf, accuracy=0.755364818634\n",
      "epoch:  18\n",
      "train mean loss=inf, accuracy=0.972192516939\n",
      "test mean loss=inf, accuracy=0.738197422335\n",
      "epoch:  19\n",
      "train mean loss=inf, accuracy=0.97433155552\n",
      "test mean loss=inf, accuracy=0.759656649802\n",
      "epoch:  20\n",
      "train mean loss=inf, accuracy=0.950802141651\n",
      "test mean loss=inf, accuracy=0.768240354859\n",
      "epoch:  21\n",
      "train mean loss=inf, accuracy=0.96042781367\n",
      "test mean loss=inf, accuracy=0.763948503226\n",
      "epoch:  22\n",
      "train mean loss=1.00367837819, accuracy=0.963636370904\n",
      "test mean loss=inf, accuracy=0.781115875479\n",
      "epoch:  23\n",
      "train mean loss=1.45509550325, accuracy=0.95614973619\n",
      "test mean loss=inf, accuracy=0.763948509877\n",
      "epoch:  24\n",
      "train mean loss=1.03274527316, accuracy=0.965775407253\n",
      "test mean loss=inf, accuracy=0.729613729301\n",
      "epoch:  25\n",
      "train mean loss=0.560709234419, accuracy=0.983957229451\n",
      "test mean loss=inf, accuracy=0.755364798169\n",
      "epoch:  26\n",
      "train mean loss=0.477698174295, accuracy=0.977540112115\n",
      "test mean loss=inf, accuracy=0.798283263337\n",
      "epoch:  27\n",
      "train mean loss=0.364063878365, accuracy=0.979679148465\n",
      "test mean loss=inf, accuracy=0.751072956769\n",
      "epoch:  28\n",
      "train mean loss=0.318043405783, accuracy=0.988235301831\n",
      "test mean loss=inf, accuracy=0.751072946536\n",
      "epoch:  29\n",
      "train mean loss=0.111175391427, accuracy=0.994652408967\n",
      "test mean loss=inf, accuracy=0.763948491203\n",
      "epoch:  30\n",
      "train mean loss=0.0860516921794, accuracy=0.994652408967\n",
      "test mean loss=inf, accuracy=0.763948501435\n",
      "epoch:  31\n",
      "train mean loss=0.972893754653, accuracy=0.965775401197\n",
      "test mean loss=inf, accuracy=0.742489273968\n",
      "epoch:  32\n",
      "train mean loss=inf, accuracy=0.975401075129\n",
      "test mean loss=inf, accuracy=0.763948499645\n",
      "epoch:  33\n",
      "train mean loss=0.17921097018, accuracy=0.991443858427\n",
      "test mean loss=inf, accuracy=0.759656658244\n",
      "epoch:  34\n",
      "train mean loss=0.111685379184, accuracy=0.992513373574\n",
      "test mean loss=inf, accuracy=0.785407718671\n",
      "epoch:  35\n",
      "train mean loss=0.170383317906, accuracy=0.99358289127\n",
      "test mean loss=inf, accuracy=0.781115865247\n",
      "epoch:  36\n",
      "train mean loss=0.0803752157914, accuracy=0.996791445954\n",
      "test mean loss=inf, accuracy=0.776824034079\n",
      "epoch:  37\n",
      "train mean loss=0.228448372693, accuracy=0.991443858427\n",
      "test mean loss=inf, accuracy=0.781115875479\n",
      "epoch:  38\n",
      "train mean loss=0.0380050226571, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.789699568513\n",
      "epoch:  39\n",
      "train mean loss=0.0364070705467, accuracy=0.998930482303\n",
      "test mean loss=inf, accuracy=0.772532184237\n",
      "epoch:  40\n",
      "train mean loss=0.0874776161546, accuracy=0.994652408967\n",
      "test mean loss=inf, accuracy=0.77682403587\n",
      "epoch:  41\n",
      "train mean loss=0.0756094418385, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.785407718671\n",
      "epoch:  42\n",
      "train mean loss=0.0401675520256, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.793991411704\n",
      "epoch:  43\n",
      "train mean loss=7.93110611194e-06, accuracy=1.0\n",
      "test mean loss=inf, accuracy=0.798283263337\n",
      "epoch:  44\n",
      "train mean loss=0.00411213360694, accuracy=0.997860964607\n",
      "test mean loss=inf, accuracy=0.785407739136\n",
      "epoch:  45\n",
      "train mean loss=inf, accuracy=0.95935829183\n",
      "test mean loss=inf, accuracy=0.768240353069\n",
      "epoch:  46\n",
      "train mean loss=inf, accuracy=0.963636375366\n",
      "test mean loss=inf, accuracy=0.776824047893\n",
      "epoch:  47\n",
      "train mean loss=inf, accuracy=0.917647062457\n",
      "test mean loss=inf, accuracy=0.819742499247\n",
      "epoch:  48\n",
      "train mean loss=inf, accuracy=0.951871660304\n",
      "test mean loss=inf, accuracy=0.802575104738\n",
      "epoch:  49\n",
      "train mean loss=inf, accuracy=0.961497329773\n",
      "test mean loss=inf, accuracy=0.768240353069\n",
      "epoch:  50\n",
      "train mean loss=inf, accuracy=0.980748672855\n",
      "test mean loss=inf, accuracy=0.781115875479\n",
      "epoch:  51\n",
      "train mean loss=0.431780190177, accuracy=0.980748666162\n",
      "test mean loss=inf, accuracy=0.785407728903\n",
      "epoch:  52\n",
      "train mean loss=0.301749039554, accuracy=0.983957221801\n",
      "test mean loss=inf, accuracy=0.763948491203\n",
      "epoch:  53\n",
      "train mean loss=0.269326226724, accuracy=0.987165785091\n",
      "test mean loss=inf, accuracy=0.785407728903\n",
      "epoch:  54\n",
      "train mean loss=inf, accuracy=0.980748666162\n",
      "test mean loss=inf, accuracy=0.77253219626\n",
      "epoch:  55\n",
      "train mean loss=inf, accuracy=0.982887706655\n",
      "test mean loss=inf, accuracy=0.768240342836\n",
      "epoch:  56\n",
      "train mean loss=0.425402142279, accuracy=0.983957224351\n",
      "test mean loss=inf, accuracy=0.781115887503\n",
      "epoch:  57\n",
      "train mean loss=0.368032014215, accuracy=0.987165781585\n",
      "test mean loss=inf, accuracy=0.78111587727\n",
      "epoch:  58\n",
      "train mean loss=0.155282234748, accuracy=0.993582888721\n",
      "test mean loss=inf, accuracy=0.776824025637\n",
      "epoch:  59\n",
      "train mean loss=0.531857685074, accuracy=0.987165779035\n",
      "test mean loss=inf, accuracy=0.811158806213\n",
      "epoch:  60\n",
      "train mean loss=inf, accuracy=0.995721929214\n",
      "test mean loss=inf, accuracy=0.802575114971\n"
     ]
    }
   ],
   "source": [
    "cv = 5\n",
    "n_samples = len(x_data)\n",
    "fold_size = n_samples // cv\n",
    "scores = []\n",
    "masks = []\n",
    "for fold in range(cv):\n",
    "    print fold\n",
    "    test_mask = np.zeros(n_samples, dtype=bool)\n",
    "    test_mask[fold * fold_size:(fold+1)*fold_size] = True\n",
    "    x_test, t_test = x_data[test_mask], t_data[test_mask]\n",
    "    x_train, t_train = x_data[~test_mask], t_data[~test_mask]\n",
    "    N=len(t_train)\n",
    "    N_test=len(t_test)\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    \n",
    "    # Load model\n",
    "    import cnn\n",
    "    model = cnn.CNN2()\n",
    "    \n",
    "    # setup GPU\n",
    "    if gpu_flag >= 0:\n",
    "        cuda.check_cuda_available()\n",
    "    xp = cuda.cupy if gpu_flag >=0 else np\n",
    "    if gpu_flag >= 0:\n",
    "        cuda.get_device(gpu_flag).use()\n",
    "        model.to_gpu()\n",
    "    \n",
    "    #Setup optimizer(Adam)\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "        \n",
    "    for epoch in six.moves.range(1,n_epoch +1):\n",
    "        print 'epoch: ', epoch\n",
    "    \n",
    "        #training\n",
    "        perm = np.random.permutation(N)\n",
    "        sum_acc = 0\n",
    "        sum_loss = 0\n",
    "        for i in six.moves.range(0,N,batchsize):\n",
    "            x_batch = xp.asarray(x_train[perm[i:i + batchsize]])\n",
    "            t_batch = xp.asarray(t_train[perm[i:i + batchsize]])\n",
    "        \n",
    "            optimizer.zero_grads()\n",
    "            loss, acc = model.forward(x_batch, t_batch)\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "\n",
    "            sum_loss += float(loss.data)*len(t_batch)\n",
    "            sum_acc  += float(acc.data)*len(t_batch)\n",
    "        \n",
    "        train_loss.append([epoch,sum_loss/N])\n",
    "        train_acc.append([epoch,sum_acc/N])\n",
    "    \n",
    "        print \"train mean loss={}, accuracy={}\".format(sum_loss/N, sum_acc/N)\n",
    "    \n",
    "        #evaluation\n",
    "        sum_acc = 0\n",
    "        sum_loss = 0\n",
    "        for i in six.moves.range(0,N_test,batchsize):\n",
    "            x_batch = xp.asarray(x_test[i:i+batchsize])\n",
    "            t_batch = xp.asarray(t_test[i:i+batchsize])\n",
    "        \n",
    "            loss, acc = model.forward(x_batch, t_batch, train=False)\n",
    "        \n",
    "            sum_loss += float(loss.data)*len(t_batch)\n",
    "            sum_acc  += float(acc.data)*len(t_batch)\n",
    "        \n",
    "        test_loss.append([epoch,sum_loss/N_test])\n",
    "        test_acc.append([epoch,sum_acc/N_test])\n",
    "\n",
    "        print \"test mean loss={}, accuracy={}\".format(sum_loss/N_test, sum_acc/N_test)\n",
    "    \n",
    "    train_loss = np.asarray(train_loss)\n",
    "    train_acc = np.asarray(train_acc)\n",
    "    test_loss = np.asarray(test_loss)\n",
    "    test_acc = np.asarray(test_acc)\n",
    "    scores.append(np.max(test_acc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.82403434422906374,\n",
       " 0.79828326691885365,\n",
       " 0.84549356990617741,\n",
       " 0.80686694971993245,\n",
       " 0.81974249924712939]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76923077,  0.78205128,  0.77350427,  0.78632479,  0.79741379])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statics 3.9242412514\n",
      "p-value 0.00439210967026\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "t=stats.ttest_ind(scores, scores_area)\n",
    "print \"T-statics\", t[0]\n",
    "print \"p-value\", t[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Plot&save graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc67887e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data=[scores, scores_area]\n",
    "# \n",
    "bp = ax.boxplot(data)\n",
    "\n",
    "ax.set_xticklabels([\"Image\", 'Size'])\n",
    "plt.grid()\n",
    "plt.xlabel('Test')\n",
    "plt.ylabel('Test_accuracy')\n",
    "\n",
    "plt.title('')\n",
    "plt.ylim([0.75,0.85])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dic={}\n",
    "dic[\"Image\"]=scores\n",
    "dic[\"Size\"]=scores_area\n",
    "\n",
    "with open('accuracy1.dump','w') as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('accuracy.dump','r') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
